{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\", \n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\", \n",
    "    \"Upgrade-Insecure-Requests\": \"1\", \n",
    "    \"Referer\": \"https://www.google.com/\",\n",
    "    \"User-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url, headers=custom_headers)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error in getting webpage\")\n",
    "        exit(-1)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"lxml\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(reviewUrl):\n",
    "\n",
    "    soup = get_soup(reviewUrl)\n",
    "    review_elements = soup.select(\"div.review\")\n",
    "\n",
    "    scraped_reviews = []\n",
    "\n",
    "    for item in review_elements:\n",
    "\n",
    "        author = item.find('span', {'class': 'a-profile-name'}).text.strip() if item.find('span', {'class': 'a-profile-name'}) else ''\n",
    "\n",
    "        rating = item.find('i', {'data-hook': 'review-star-rating'}).text.strip()[0] if item.find('i', {'data-hook': 'review-star-rating'}) else ''\n",
    "\n",
    "        title = item.find('a', {'data-hook': 'review-title'}).text.strip().split('\\n', 1)[1] if item.find('a', {'data-hook': 'review-title'}) else ''\n",
    "\n",
    "        content = item.find('span', {'data-hook': 'review-body'}).text.strip() if item.find('span', {'data-hook': 'review-body'}) else ''\n",
    "\n",
    "        date = item.find('span', {'data-hook': 'review-date'}).text.strip().split('on ', 1)[1]  if item.find('span', {'data-hook': 'review-date'}) else ''\n",
    "\n",
    "        \n",
    "        r = {\n",
    "            \"author\": author,\n",
    "            \"rating\": rating,\n",
    "            \"title\": title,\n",
    "            \"content\": content,\n",
    "            \"date\": date\n",
    "        }\n",
    "\n",
    "        scraped_reviews.append(r)\n",
    "\n",
    "    return scraped_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalPages(productUrl):\n",
    "    soup = get_soup(productUrl)\n",
    "    reviews = soup.find('div', {'data-hook':\"cr-filter-info-review-rating-count\"})\n",
    "    print(reviews.text.strip().split(', ')[1].split(\" \")[0])\n",
    "    return int(reviews.text.strip().split(', ')[1].split(\" \")[0].replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.co.uk/Yaheetech-Dining-Kitchen-Breakfast-Stools/product-reviews/B0C167TLF8/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=3\n",
      "56\n",
      "Running for page 1\n",
      "https://www.amazon.co.uk/Yaheetech-Dining-Kitchen-Breakfast-Stools/product-reviews/B0C167TLF8/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&pageNumber=1\n",
      "            author rating                            title  \\\n",
      "0      Sarah white      5  Great quality for a great price   \n",
      "1             Tina      5      Sturdy and easy to assemble   \n",
      "2               KC      4           Brilliant little table   \n",
      "3      morganmarie      5                            great   \n",
      "4  marguerite Bone      5          Fabulous table & stools   \n",
      "5        Nickipo76      5    Great build quality and value   \n",
      "6              Meh      5                          Amazing   \n",
      "7       Cheee of E      4                         Stickers   \n",
      "8    Jade Williams      4                Looks really good   \n",
      "9            donna      5                           Sturdy   \n",
      "\n",
      "                                             content             date  \n",
      "0  I bought This abit weary but it turned out to ...      7 June 2024  \n",
      "1  This table and stools fits into my living room...   9 January 2024  \n",
      "2  For the price this is the most beautiful, stur...    30 April 2024  \n",
      "3  its the perfect size, quality is good and its ...       3 May 2024  \n",
      "4  We bought 2 of these table and stools. For our...  3 November 2023  \n",
      "5  Perfect table for our small kitchen/dining roo...      4 June 2024  \n",
      "6  Decent price. Sturdy table and stool set. Easy...  17 January 2024  \n",
      "7  Table is lovely, easy to assembleHowever - the...      2 June 2024  \n",
      "8  Looks really good, but doesnâ€™t take long for t...     6 April 2024  \n",
      "9  Worth the money and fits lovely sturdy for wha...      15 May 2024  \n"
     ]
    }
   ],
   "source": [
    "iter_reviews = []\n",
    "search_url = \"https://www.amazon.co.uk/Yaheetech-Dining-Kitchen-Breakfast-Stools/product-reviews/B0C167TLF8/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews&\"\n",
    "reviewUrl = search_url + \"pageNumber=\" + str(3)\n",
    "print(reviewUrl)\n",
    "totalPage = totalPages(search_url)\n",
    "\n",
    "for i in range(1):\n",
    "    print(f\"Running for page {i+1}\")\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        reviewUrl = search_url + \"pageNumber=\" + str(i+1)\n",
    "        print(reviewUrl)\n",
    "        data = get_reviews(reviewUrl)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "   \n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "df.to_csv(\"xboxControllerReview.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
